---
title: "Methods Power Study - Pilot Sample Size Simulation"
author: "Erin M. Buchanan"
date: "Last Knitted: `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Reviewer-requested simulation using semanticprimeR: Quantifies variability from pilot-based cutoffs and reports: (a) average final N and SE, (b) achieved power and SE

## Libraries

```{r}
# install.packages("remotes") 
# remotes::install_github("SemanticPriming/semanticprimeR")
library(semanticprimeR)
library(dplyr)
library(purrr)
library(tidyr)
library(broom)
library(ggplot2)
library(stringr)
set.seed(20250813)
```

## Parameters

```{r eval = F}
# ones to change for small, medium, large
scale_min         <- 0
scale_max         <- 3000
mu                <- 1000
mu_sigma          <- 150
sigma             <- 400
sigma_sigma       <- 200
smallest_sigma    <- 20
digits            <- 0
labels            <- "large_large"

# small - small 1, 7, 4, .25, 2, .2, .02, 0, "small_small" done
# small - medium 1, 7, 4, .25, 2, .4, .04, 0, "small_medium" done
# small - large 1, 7, 4, .25, 2, .8, .08, 0, "small_large" done
# medium - small 0, 100, 50, 10, 25, 4, .4, 0, "medium_small" done
# medium - medium 0, 100, 50, 10, 25, 8, .8, 0, "medium_medium" done
# medium - large 0, 100, 50, 10, 25, 16, 1.6, 0, "medium_large" done
# large - small 0, 3000, 1000, 150, 400, 50, 5, 0, "large_small" done
# large - medium 0, 3000, 1000, 150, 400, 100, 10, "large_medium" done
# large - large 0, 3000, 1000, 150, 400, 200, 20, "large_large" done

# ones to keep consistent 
n_items           <- 30
pop_scores_per_it <- 1000           # large to approximate "truth"
target_q_percent  <- 0.40           # 4th decile (fixed)
percent_levels    <- c(80,85,90,95) # targets in pipeline
n_pilot_reps      <- 100            # 100 researchers all doing the same thing
minN              <- 20
maxN              <- 300
stepN             <- 5
pilot_sizes       <- c(20, 25, 30, 35, 40)
```

## True Population 

```{r eval = F}
# create a large population of items
pop <- simulate_population(
  mu = mu, 
  mu_sigma = mu_sigma,
  sigma = sigma, 
  sigma_sigma = sigma_sigma,
  number_items = n_items,
  number_scores = pop_scores_per_it,
  smallest_sigma = smallest_sigma,
  min_score = scale_min,
  max_score = scale_max,
  digits = digits
)

# get population SD 
pop_item_sigma <- pop %>%
  dplyr::group_by(item) %>%
  dplyr::summarise(sigma = sd(score), .groups = "drop")
```

## Pilot Helper Function

```{r eval = F}
# researcher running one pilot study --> uses variables from above 
run_one_pilot <- function(rep_id, pilot_size) {

  # Draw a pilot sample per item from the population
  pilot <- pop %>%
    group_by(item) %>%
    slice_sample(n = pilot_size, replace = FALSE) %>%
    ungroup()

  # Step 2: get pilot-based cutoff & prop_var
  cutoff <- calculate_cutoff(
    population     = pilot,
    grouping_items = "item",
    score          = "score",
    minimum        = scale_min,
    maximum        = scale_max
  )
  pilot_cut <- cutoff$cutoff
  prop_var  <- cutoff$prop_var

  # Steps 3–5: simulate from pilot; proportion below pilot_cut; correction t0 final N
  samp_list <- simulate_samples(
    start = minN, 
    stop = maxN, 
    increase = stepN,
    population = pilot, 
    replace = TRUE, 
    nsim = 500,
    grouping_items = "item"
  )

  prop_tbl <- calculate_proportion(
    samples = samp_list,
    cutoff = pilot_cut,
    grouping_items = "item",
    score = "score"
  )

  corrected <- calculate_correction(
    proportion_summary   = prop_tbl,
    pilot_sample_size    = pilot_size,
    proportion_variability = prop_var,
    power_levels         = percent_levels
  )

  # Map noisy percent_below to nearest intended target level
  final_Ns <- corrected %>%
    mutate(target_level = percent_levels[
      sapply(percent_below, function(x) which.min(abs(percent_levels - x)))
    ]) %>%
    group_by(target_level) %>%
    summarise(final_N = ceiling(min(corrected_sample_size, na.rm = TRUE)), .groups = "drop")

  # Evaluate precision achieved at final N (vs TRUE population threshold)
  out <- map_dfr(seq_len(nrow(final_Ns)), function(i) {
    
    # target_pct is just a record of what proportion we were trying for
    target_pct <- final_Ns$target_level[i]
    
    #	N_final is how many participants/items you’d actually collect in the main study according to the pilot’s advice.
    N_final    <- final_Ns$final_N[i]
    
    # pretend to actually collect data based on that final sample size 
    dat_final <- pop %>%
      group_by(item) %>% 
      slice_sample(n = N_final, replace = TRUE) %>% 
      ungroup()

    # Get the SE for each item in this simulated final dataset.
    item_SE_final <- dat_final %>%
      group_by(item) %>%
      summarise(SE = sd(score)/sqrt(n()), .groups = "drop")
    
    # create the SE from the population sigma, gold standard cutoff 
    true_SE_i_at_N      <- pop_item_sigma$sigma / sqrt(N_final)
    pop_threshold_at_N  <- stats::quantile(true_SE_i_at_N, 
                                           probs = target_q_percent, 
                                           names = FALSE)
    
    # align order just to be safe
    item_ids <- dplyr::arrange(item_SE_final, item)$item
    SE_obs   <- dplyr::arrange(item_SE_final, item)$SE
    SE_true  <- true_SE_i_at_N[order(dplyr::arrange(pop_item_sigma, item)$item)]
    
    # per-item errors
    se_err        <- SE_obs - SE_true
    se_rel_err    <- se_err / SE_true
    mae           <- mean(abs(se_err))
    rmse          <- sqrt(mean(se_err^2))
    bias          <- mean(se_err)
    mean_rel_err  <- mean(se_rel_err)
    cov_within_5p <- mean(abs(se_rel_err) <= 0.05)  # within ±5% of true SE
    cov_within_10p<- mean(abs(se_rel_err) <= 0.10)  # within ±10%
    
    # percent-below metrics (as before, now using threshold at this N)
    pct_below_pop   <- mean(SE_obs <= pop_threshold_at_N)
    pct_below_pilot <- mean(SE_obs <= pilot_cut)
    delta_pct_pop   <- pct_below_pop - target_q_percent  # calibration vs truth
    
    # cutoff error (pilot threshold vs true threshold at this N)
    cutoff_error      <- pilot_cut - pop_threshold_at_N
    cutoff_rel_error  <- cutoff_error / pop_threshold_at_N
    
    tibble::tibble(
      pilot_rep              = rep_id,
      pilot_size             = pilot_size,
      target_percent         = target_pct,
      final_N                = N_final,
      # thresholded metrics
      pct_items_below_pop    = pct_below_pop,
      pct_items_below_pilot  = pct_below_pilot,
      delta_pct_pop          = delta_pct_pop,
      # continuous accuracy of SEs
      se_bias                = bias,
      se_mae                 = mae,
      se_rmse                = rmse,
      se_mean_rel_err        = mean_rel_err,
      se_cov_within_5pct     = cov_within_5p,
      se_cov_within_10pct    = cov_within_10p,
      # cutoff accuracy
      cutoff_error           = cutoff_error,
      cutoff_rel_error       = cutoff_rel_error
    )
  })

  write.csv(out, paste0("simulation_pilot/pilot_sim", 
                        rep_id, "_", pilot_size, "_", labels, ".csv"), row.names = F)
  out
}
```

## Run Multiple Researcher's Pilot Studies

```{r eval = F}
all_results <- map_dfr(pilot_sizes, function(ps) {
  map_dfr(seq_len(n_pilot_reps), function(r) run_one_pilot(r, ps))
})
# beepr::beep()
write.csv(all_results, 
          paste0("simulation_pilot/pilot_simulation_", labels, ".csv"),
          row.names = F)
```

## Create Overall File

```{r}
file.list <- list.files(
  path = "simulation_pilot",
  pattern = "pilot_sim.*\\.csv$",
  full.names = TRUE
)

files.df <- lapply(file.list, function(f) {
  
  # Extract just the filename
  fname <- basename(f)
  
  # Remove extension
  fname_noext <- str_remove(fname, "\\.csv$")
  
  # Get the part after the last underscore (e.g., "small_large")
  suffix <- str_extract(fname_noext, "[^_]+_[^_]+$")
  
  # Split into two parts
  parts <- str_split(suffix, "_", simplify = TRUE)
  
  read.csv(f) %>%
    mutate(
      source_file = fname,
      scale_size = parts[1],
      variance_size   = parts[2]
    )
  
}) %>%
  bind_rows()

counts <- files.df %>% 
  select(scale_size, variance_size, pilot_size, pilot_rep) %>% 
  unique() %>% 
  group_by(scale_size, variance_size, pilot_size) %>% 
  count()

# View(counts)
write.csv(files.df, "simulation_pilot/pilot_simulation_final.csv", row.names = F)
```